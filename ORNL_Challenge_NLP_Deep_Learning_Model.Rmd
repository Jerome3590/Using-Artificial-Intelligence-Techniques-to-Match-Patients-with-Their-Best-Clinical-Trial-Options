---
title: "ORNL Deep Learning Model for Data Science Challenge"
author: "Jerome Dixon"
date: "8/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(reticulate)
use_condaenv("ORNL")

```


```{r}

library(here)
library(readxl)
library(httr)
library(jsonlite)
library(dplyr)
library(tidyr)
library(magrittr)
library(aws.s3)
library(tidyverse)
library(kableExtra)
library(purrr)
library(data.table)
library(rsample)
library(caret)
library(recipes)
library(mltools)
library(keras)

```


```{r Import DL dataset}


final_DL_df <- read_csv("data/nlp_stage3/final_DL_df.csv")

final_DL_df %<>% select(2:4)

final_DL_df$target_site <- as.factor(final_DL_df$target_site)


```



```{r Training datasets}

# Split test/training sets
set.seed(1997)

train_test_split <- initial_split(final_DL_df, prop = 0.8)

# Retrieve train and test sets
train_tbl <- training(train_test_split)
test_tbl  <- testing(train_test_split)


```


```{r}

# Create recipe
rec_obj <- recipe(target_site ~ ., data = train_tbl) %>%
  step_log(eigencentrality) %>%
  step_log(eigencentrality_adjusted) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_center(all_predictors(), -all_outcomes()) %>%
  step_scale(all_predictors(), -all_outcomes()) %>%
  prep(data = train_tbl)




```



```{r Model Data Prep}

# Predictors
x_train_tbl <- bake(rec_obj, new_data = train_tbl) %>% select(-target_site)
x_test_tbl  <- bake(rec_obj, new_data = test_tbl) %>% select(-target_site)

glimpse(x_train_tbl)


```


```{r One Hot Encoding}

# Predictors
y_train_target <- bake(rec_obj, new_data = train_tbl) %>% select(target_site)
y_test_target  <- bake(rec_obj, new_data = test_tbl) %>% select(target_site)

train_one_hot <- as.vector(one_hot(as.data.table(y_train_target)))
test_one_hot <- as.vector(one_hot(as.data.table(y_train_target)))


```



```{r}

# Creating the model

model <- keras_model_sequential()
model %>% 
  layer_dense(units = 2,
              kernel_regularizer = regularizer_l2(0.001),
              activation = "relu",
              input_shape = c(2)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 50,
              kernel_regularizer = regularizer_l2(0.001),
              activation = "relu") %>% 
  layer_dense(units = 25,
              activation = "softmax")
summary(model)


```


```{r}

# Compiling the model
model %>% compile(loss = "categorical_crossentropy",
                  optimizer = "adam",
                  metrics = c("accuracy"))



```



```{r}


history <- model %>% 
  fit(as.matrix(x_train_tbl),
      as.matrix(train_one_hot),
      epoch = 10,
      batch_size = 1,
      validation_split = 0.2,
      verbose= 2)


```


```{r}

plot(history)

```


```{r}

model %>% 
  evaluate(x_test_tbl,
           test_one_hot)


```




```{r}


pred <- model %>% 
  predict_classes(x_test)

table(Predicted = pred,
      Actual = y_test_actual)



```


```{r}

prob <- model %>% 
  predict_proba(x_test)
cbind(prob,
      pred,
      y_test_actual)



```

